2025-07-17 16:48:23,671 - INFO - training data size=7445
2025-07-17 16:48:23,672 - INFO - ----start training-----

2025-07-17 16:48:23,672 - INFO - epoch=[1/5]
2025-07-17 17:05:45,997 - INFO - [Epoch 1] Avg Train Acc: 0.8606, Avg F1: 0.8592
2025-07-17 17:05:46,010 - INFO - Saved best model to pth/qam_weibo_epoch1.pth with F1: 0.8592
2025-07-17 17:05:46,143 - INFO - training loss : similarity_loss=0.428490    detection_loss=0.273593
2025-07-17 17:05:46,144 - INFO - training time=17m22s
2025-07-17 17:05:46,144 - INFO - epoch=[2/5]
2025-07-17 17:22:42,579 - INFO - [Epoch 2] Avg Train Acc: 0.8955, Avg F1: 0.8943
2025-07-17 17:22:42,601 - INFO - Saved best model to pth/qam_weibo_epoch2.pth with F1: 0.8943
2025-07-17 17:22:42,767 - INFO - training loss : similarity_loss=0.392907    detection_loss=0.335329
2025-07-17 17:22:42,767 - INFO - training time=16m56s
2025-07-17 17:22:42,767 - INFO - epoch=[3/5]
2025-07-17 17:39:27,285 - INFO - [Epoch 3] Avg Train Acc: 0.8935, Avg F1: 0.8923
2025-07-17 17:39:27,424 - INFO - training loss : similarity_loss=0.257997    detection_loss=0.459766
2025-07-17 17:39:27,424 - INFO - training time=16m44s
2025-07-17 17:39:27,424 - INFO - epoch=[4/5]
2025-07-17 17:56:45,963 - INFO - [Epoch 4] Avg Train Acc: 0.8980, Avg F1: 0.8969
2025-07-17 17:56:45,981 - INFO - Saved best model to pth/qam_weibo_epoch4.pth with F1: 0.8969
2025-07-17 17:56:46,173 - INFO - training loss : similarity_loss=0.312189    detection_loss=0.145390
2025-07-17 17:56:46,174 - INFO - training time=17m18s
2025-07-17 17:56:46,174 - INFO - epoch=[5/5]
2025-07-17 18:13:45,178 - INFO - [Epoch 5] Avg Train Acc: 0.8964, Avg F1: 0.8954
2025-07-17 18:13:45,347 - INFO - training loss : similarity_loss=0.335799    detection_loss=0.369487
2025-07-17 18:13:45,348 - INFO - training time=16m59s
2025-07-17 18:13:45,389 - INFO - Loaded best model from pth/qam_weibo_epoch4.pth
2025-07-17 18:14:51,361 - INFO - training data size=7445
2025-07-17 18:14:51,361 - INFO - test data size=1969
2025-07-17 18:14:51,361 - INFO - test result: accuracy=0.810056    precision=0.758913    recall=0.908537    f1=0.827012
